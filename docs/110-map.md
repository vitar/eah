# ⭐ **Translation Map: Connecting Estimation Methods Across the Delivery Lifecycle**

*A unified framework that aligns estimation for RFP, discovery, delivery, forecasting, and value.*

---

# **1. Purpose of This Translation Map**

Every stage of the lifecycle uses a different estimation method:

* Pre-sales → FTE & cost
* Delivery → story points & velocity
* Forecasting → flow metrics
* Trade-offs → value vs. effort
* Design/Architecture → discovery workload

Historically, these methods do not align, creating:

* mismatched expectations
* drift between RFP and delivery
* inflated velocity
* late scope cuts
* unpredictable timelines

This map creates a **single coherent translation layer** grounded in **Complexity** and **Uncertainty**, so each method reinforces the others.

---

# **2. The Translation Challenge (Why We Need This Map)**

Common questions teams face:

* “How does the cost estimate connect to story points?”
* “Why does velocity go up but timeline still slips?”
* “Why does RFP complexity disappear during delivery?”
* “Why is design always under-estimated?”
* “How do we detect when scope has actually changed?”

This map answers them.

---

# **3. The Core Model: Two Dimensions, Three Outputs**

### **Input Dimensions**

1. **Complexity (known work)**
2. **Uncertainty (unknown work)**

### **Three Outputs**

1. **Initial effort (RFP)**
2. **Delivery effort (story points & flow)**
3. **Forecasting (probabilistic timelines)**

These outputs must be derived from the same backbone.

---

# **4. Mapping Complexity to Different Estimation Methods**

Below are the most common methods in your organization and how complexity connects them.

---

## **4.1. Complexity → FTE Estimates (RFP stage)**

At RFP, we estimate cost in FTE-weeks/months.

### **Translation:**

**Complexity Score** determines the multiplier applied to base FTE effort.

Example multiplier table:

| Complexity Sum | Multiplier |
| -------------- | ---------- |
| 0–3            | ×1.0       |
| 4–7            | ×1.2       |
| 8–12           | ×1.5       |
| 13+            | ×2.0       |

### Example:

* Base effort = 2 dev-weeks
* Complexity = 10 → multiplier ×1.5
* Total = 3 dev-weeks (before uncertainty)

This is clean, defensible, and scalable.

---

## **4.2. Complexity → Story Points (Delivery stage)**

Story points don’t disappear.
They become a *refinement* of the complexity baseline.

### **Translation:**

Complexity levels anchor SP ranges.

| Complexity Level | SP Range     |
| ---------------- | ------------ |
| Low (1–3)        | 1–3          |
| Medium (4–7)     | 5–8          |
| High (8–12)      | 13–21        |
| Extreme (13+)    | >21 or split |

This prevents silent scope inflation hidden inside SP re-estimation.

---

## **4.3. Complexity → Team Composition & Skills**

A high complexity driver such as:

* integration
* domain logic
* NFR
* compliance
* unclear ownership

…means we need correct staffing early.

### **Translation examples:**

* High integration complexity → Architect involvement full cycle
* High UX complexity → PD workload increases
* High domain logic complexity → BA workload increases

This corrects the blind spot where PM/PD/BA effort is assumed rather than estimated.

---

## **4.4. Complexity → Design & Discovery Effort**

Discovery is not “overhead.”
It is complexity translation.

### **Translation:**

* High domain complexity → longer BA clarification
* High UX complexity → more PD design cycles
* High integration complexity → architecture mapping
* High uncertainty → dependency mapping, spikes

This links discovery/design to reality instead of guessing.

---

# **5. Mapping Uncertainty Across Methods**

Uncertainty is a distinct dimension.
It affects:

* risk
* confidence
* cost buffers
* timeline ranges
* probability of scope drift

---

## **5.1. Uncertainty → Risk Modifiers (RFP)**

Example multipliers:

| Uncertainty Score | Multiplier |
| ----------------- | ---------- |
| 0–1               | ×1.0       |
| 2                 | ×1.3       |
| 3                 | ×1.6       |
| 5                 | ×2.0       |

### Example:

Effort after complexity = 3 dev-weeks
Uncertainty multiplier = ×1.6
Final = 4.8 → round to 5 dev-weeks

---

## **5.2. Uncertainty → PERT Ranges (best / likely / worst)**

Uncertainty maps directly to variance.

* Low uncertainty → tight range
* High uncertainty → wide range

Example:

* Likely: 5 weeks
* Low U → 4–6
* Medium U → 3–8
* High U → 2–12

This avoids the lie of a single-scenario estimate.

---

## **5.3. Uncertainty → Discovery Workload (delivery readiness)**

High uncertainty automatically means:

* spikes
* PoCs
* stakeholder sessions
* alignment workshops
* design explorations

Teams can no longer skip clarification work.

---

## **5.4. Uncertainty → Probability of Drift**

This becomes the early-warning indicator.

If uncertainty stays high during delivery → timeline will slip.

---

# **6. Combining Complexity + Uncertainty Across Methods**

### Combined matrix:

| Complexity → | Low (1–3)    | Medium (4–7)   | High (8–12)         | Extreme (13+)            |
| ------------ | ------------ | -------------- | ------------------- | ------------------------ |
| **Low U**    | predictable  | predictable    | slower but stable   | stable if well-staffed   |
| **Medium U** | mild drift   | moderate drift | large drift         | almost guaranteed change |
| **High U**   | severe drift | severe drift   | major re-estimation | not feasible             |

This table explains “why projects slip” *without blaming velocity*.

---

# **7. Mapping to Forecasting**

### Complexity → batch size

Higher complexity = larger stories = larger cycle time

### Uncertainty → variance

Higher uncertainty = wider spread in Monte Carlo simulation

### Complexity baseline → throughput

Provides a clear comparison of planned vs. actual

### Complexity drift → early-warning signals

If drift grows faster than throughput, the project is behind.

---

# **8. Mapping to Value & Trade-Offs**

This model makes prioritization empirical:

### **High-value, low-complexity → do immediately**

### **High-value, high-complexity → invest carefully / scope slices**

### **Low-value, high-complexity → cut early**

### **Low-value, low-complexity → opportunistic**

This matches the 3SF value cycle (product ↔ client).

---

# **9. Mapping to 3SF (3-in-3 SDLC Framework)**

### **Engagement Line (client ↔ vendor)**

* Complexity & Uncertainty create **transparent RFP conversations**
* Fewer surprises
* More realistic proposals
* Trust increases

### **Delivery Line (vendor ↔ product)**

* Story points become meaningful
* Velocity pressure decreases
* Complexity drift becomes visible
* Predictability increases

### **Value Line (product ↔ client)**

* Tradeoffs become transparent
* Prioritization becomes data-driven
* Scope decisions align to business outcomes
* Value delivery becomes measurable

This model strengthens all 3 connections in the 3SF triangle.

---

# **10. FAQ: What This Page Answers**

### **Q: How does the RFP estimate connect to story points?**

**A:** Through complexity mapping.
They share the same backbone.

### **Q: Why does velocity grow but timeline still slip?**

**A:** Because complexity drift remained invisible.
Velocity cannot compensate for scope inflation.

### **Q: How do we detect scope change early?**

**A:** Re-score complexity each sprint.
Compare to the baseline.

### **Q: How do we prioritize effectively?**

**A:** Use the value × complexity matrix.

### **Q: Does this replace existing tools?**

**A:** No.
It aligns them.

---

# **11. Next Page**

Next we create:

### **Page 3: Scoring Sheet (Model + Tool)**

It will include:

* complexity scoring
* uncertainty scoring
* complexity baseline creation
* drift tracking
* refinements during delivery
* Excel/Confluence versions
* integration with project dashboards
