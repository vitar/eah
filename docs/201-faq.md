# ⭐ **How This Model Fits With Existing RFP and Fixed-Bid Estimation Processes?**

> **Our RFP process stays the same.  
> What changes is that estimates now have a structured complexity & uncertainty model behind them, making cost, scope, and timelines more predictable and transparent — and giving Delivery the context it needs to succeed.**

---

*How to align cost estimation, complexity scoring, and delivery predictability without replacing current methods.*

---

## **1. Why This Question Matters**

Every organization already has a way to answer the big pre-sales questions:

* “How much will it cost?”
* “How many people do we need?”
* “How long will it take?”

These are answered through:

* FTE-based effort modeling
* sprint counts
* blended rates
* role allocations
* overhead and risk modifiers

The concern is:
**Does the complexity & uncertainty model change these workflows?
Does it replace them?
Does it require new tools?**

The short answer:
**No — it strengthens them. It makes them more honest, traceable, and predictable.**

This page explains how.

---

# **2. What Stays the Same**

Your existing RFP estimation workflow **does not disappear**.

Teams still:

* create EPIC / capability lists
* estimate effort per component
* calculate needed roles
* compute team cost
* apply risk buffers
* produce a price
* respond to RFPs on time

The organization does not change:

* pricing structure
* blended rates
* margin models
* sprint cost calculations
* role mix assumptions
* sales processes

**All existing mechanics remain fully compatible.**

---

# **3. What Changes (and Why It Matters)**

### **A. Complexity becomes the foundation for effort estimation**

Today, FTE effort is mostly based on:

* prior experience
* intuition
* heuristic judgments
* “this feels like 2 back-end devs for 10 sprints”

The new model introduces **scored complexity drivers** that make these assumptions explicit.

This improves:

* transparency
* accuracy
* confidence
* repeatability
* consistency across teams

It also reduces the risk of:

* underestimating integrations
* ignoring dependencies
* forgetting discovery/design complexity
* misjudging non-functional load
* overconfident timelines

---

### **B. Uncertainty becomes a first-class input**

Instead of applying a flat “risk modifier,” we now score uncertainty using explicit factors such as:

* unclear requirements
* missing documentation
* unknown dependencies
* unstable client ownership
* unclear UX direction
* regulatory ambiguity

This creates:

* better risk modeling
* better expectation setting
* more realistic buffers
* clear justification for contingency

---

### **C. RFP estimates become anchored to a Complexity Baseline**

The RFP estimate ceases to be a **black box** and becomes a **traceable set of assumptions**.

This baseline allows Delivery teams to:

* understand what was assumed
* understand where drift begins
* detect scope expansion early
* anchor story points to original expectations
* justify re-estimation
* protect the timeline and budget

Without a baseline, Delivery inherits a number without context.
With a baseline, they inherit a **model**.

---

# **4. How the Model Fits Into the RFP Workflow (Step-by-Step)**

Below is the exact flow, showing how little the workflow changes and how much clarity improves.

---

## ⭐ **Step 1 — Build EPIC/Capability List (Same as today)**

No changes.
This remains the starting point.

---

## ⭐ **Step 2 — Score Complexity per EPIC (New clarity layer)**

Each high-level item receives complexity scoring using 8–10 drivers.

This:

* exposes hidden effort
* identifies integration risks
* produces comparable estimates across PM/PD/BA/Architect/Dev
* reduces subjective anchoring

---

## ⭐ **Step 3 — Score Uncertainty per EPIC (New risk layer)**

This provides nuance to risk-based adjustments.

Instead of a generic “20–40% buffer,” teams apply uncertainty multipliers grounded in reality.

---

## ⭐ **Step 4 — Convert Complexity → FTE Effort (Same as today)**

The model uses your **existing cost calculator** with improved inputs.

Example:
“Base effort = 2 dev-weeks, complexity = high → multiplier ×1.5”

This is familiar to teams — no new tool required.

---

## ⭐ **Step 5 — Apply Uncertainty Multiplier (More accurate buffers)**

Uncertainty becomes the *driver* for risk buffers, not a gut feel.

High uncertainty → wider cost/timeline range
Low uncertainty → tighter range

---

## ⭐ **Step 6 — Build Team Composition (Same as today, but justified)**

PM, BA, PD, Architect effort is no longer guessed — it is **complexity-driven**.

---

## ⭐ **Step 7 — Produce RFP Cost & Timeline (Same deliverables as before)**

Nothing changes in how we prepare the final RFP package:

* scope
* assumptions
* team
* cost
* timeline
* risks

What changes is **confidence** and **alignment**.

---

# **5. How This Helps Delivery Teams (The Biggest Improvement)**

Delivery no longer receives:

* a number
* a list of EPICs
* a loosely defined timeline
* a scope spreadsheet

They now receive:

* Complexity Baseline
* Uncertainty Baseline
* assumptions per EPIC
* dependency risks
* integration challenges
* scoring rationale

This solves the #1 source of tension in most organizations:

**“RFP gave us an unrealistic estimate — now delivery must make it work.”**

With a shared model, everyone sees:

* where assumptions were strong
* where assumptions were weak
* where drift happens
* where renegotiation is justified
* where scope must be sliced
* where capacity must be adjusted

This creates transparency and strengthens trust across 3SF lines:

* Engagement (client ↔ vendor)
* Delivery (vendor ↔ product)
* Value (product ↔ client)
